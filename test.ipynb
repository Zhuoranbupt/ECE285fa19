{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as td\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "from PIL import Image\n",
    "import nntools as nt\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader import VOCDataset, myimshow\n",
    "import model\n",
    "import glob\n",
    "# from scipy.misc import imresize\n",
    "from matplotlib.pyplot import imread\n",
    "# im = imread(image.png)\n",
    "import cv2\n",
    "\n",
    "class statsmanager(nt.StatsManager):\n",
    "    def __init__self():\n",
    "        super(statsmanager,self).__init__()\n",
    "\n",
    "    def init(self):\n",
    "        super(statsmanager,self).init()\n",
    "        self.m_ap=0\n",
    "\n",
    "    def accumulate(self,loss,x,y,d):\n",
    "        #Do m_ap calculations\n",
    "        super(statsmanager,self).accumulate(loss,x,y,d)\n",
    "    \n",
    "\n",
    "    def summarize(self):\n",
    "        loss=super(statsmanager,self).summarize()\n",
    "        return {'loss':loss}\n",
    "\n",
    "def plot(self,fig,ax1, ax2 ,im):\n",
    "    ax1.set_title('Image')\n",
    "    x,y=train_set[0]\n",
    "    myimshow(x,ax=ax1)\n",
    "    ax2.set_title('Yolo Net')\n",
    "    ax2.plot([exp1.history[k][0]['loss']for k in range(exp1.epoch)],label='Training Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    fig.canvas.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "lr=1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "vgg = model.Yolo(64)\n",
    "vgg.to(device)         \n",
    "adam=torch.optim.Adam(vgg.parameters(),lr=lr)\n",
    "stats_manager=statsmanager()\n",
    "train_set=VOCDataset('/datasets/ee285f-public/PascalVOC2012/')\n",
    "valid_set=VOCDataset('/datasets/ee285f-public/PascalVOC2012/', mode=\"val\")\n",
    "x,y=train_set[0]\n",
    "\n",
    "# exp1=nt.Experiment(vgg,train_set,valid_set,adam,stats_manager,batch_size=64,output_dir=\"run2\",perform_validation_during_training=True)\n",
    "# fig, (ax1, ax2) = plt.subplots(ncols=2, nrows=1)\n",
    "# exp1.load()\n",
    "# exp1.run(num_epochs=150,plot=lambda exp:plot(exp,fig=fig,ax1=ax1, ax2=ax2 ,im=x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([7, 7, 30])\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f94041a1e80>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot(self,fig,ax1, ax2 ,im):\n",
    "    ax1.set_title('Image')\n",
    "    x,y=train_set[0]\n",
    "    myimshow(x,ax=ax1)\n",
    "    ax2.set_title('Yolo Net')\n",
    "    ax2.plot([exp1.history[k]['loss']for k in range(exp1.epoch)],label='Training Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    fig.canvas.draw()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-4b3c550e5ae5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/datasets/home/home-01/48/648/zhl003/nntools.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, num_epochs, plot)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \"\"\"\n\u001b[1;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start/Continue training from epoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c842b7289d9a>\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatsmanager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_ap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "exp1=nt.Experiment(vgg,train_set,valid_set,adam,stats_manager,batch_size=64,output_dir=\"newloss\",perform_validation_during_training=False)\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, nrows=1)\n",
    "exp1.load()\n",
    "exp1.run(num_epochs=150,plot=lambda exp:plot(exp,fig=fig,ax1=ax1, ax2=ax2 ,im=x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(pred):\n",
    "\n",
    "    \n",
    "    contain1 = pred[:,:,4].unsqueeze(2)\n",
    "    contain2 = pred[:,:,9].unsqueeze(2)\n",
    "    contain = torch.cat((contain1,contain2),2)\n",
    "    mask1 = contain > 0.1 \n",
    "    mask2 = (contain==contain.max())\n",
    "    mask = (mask1+mask2).gt(0)\n",
    "    boxes=[]\n",
    "    cls_indexs=[]\n",
    "    probs=[]\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            for b in range(2):\n",
    "              \n",
    "                xc=pred[i,j,b*5]\n",
    "                    \n",
    "                w=pred[i,j,b*5+2]\n",
    "                yc=pred[i,j,b*5+1]\n",
    "                h=pred[i,j,b*5+3]\n",
    "                xy = torch.FloatTensor([j,i])*(1./7)\n",
    "                x1=(xc-(w/2))\n",
    "                x2=(xc+(w/2))\n",
    "                y1=(yc-(h/2))\n",
    "                y2=(yc+(h/2))\n",
    "                box = pred[i,j,b*5:b*5+4]\n",
    "                bbox=torch.FloatTensor(box.size())\n",
    "                bbox[0]=x1\n",
    "                bbox[1]=y1\n",
    "                bbox[2]=x2\n",
    "                bbox[3]=y2\n",
    "                contain_prob=torch.FloatTensor([pred[i,j,b*5+4]])\n",
    "                max_prob,cls_index = torch.max(pred[i,j,10:],0)\n",
    "                if float((contain_prob*max_prob)[0]) > 0.1:\n",
    "                    boxes.append(bbox.view(1,4))\n",
    "                    cls_indexs.append(cls_index)\n",
    "                    probs.append(contain_prob*max_prob)\n",
    "    print(cls_indexs)\n",
    "    if len(boxes)==0 or len(cls_indexs)==0:\n",
    "        boxes = torch.zeros((1,4))\n",
    "        probs = torch.zeros(1)\n",
    "        cls_indexs = torch.zeros(1)\n",
    "    else:\n",
    "        boxes = torch.cat(boxes,0) #(n,4)\n",
    "        probs = torch.cat(probs,0) #(n,)\n",
    "        cls_indexs = torch.stack(cls_indexs,0) #(n,)\n",
    "    return boxes,probs,cls_indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(bboxes,scores,threshold=0.5):\n",
    "    '''\n",
    "    bboxes(tensor) [N,4]\n",
    "    scores(tensor) [N,]\n",
    "    '''\n",
    "    x1 = bboxes[:,0]\n",
    "    y1 = bboxes[:,1]\n",
    "    x2 = bboxes[:,2]\n",
    "    y2 = bboxes[:,3]\n",
    "    areas = (x2-x1) * (y2-y1)\n",
    "    _,order = scores.sort(0,descending=True)\n",
    "    keep = []\n",
    "    order1=order.numpy()\n",
    "    while order1.size > 0:\n",
    "\n",
    "        if order1.size == 1:\n",
    "            i = order1\n",
    "            keep.append(i)\n",
    "            break\n",
    "        i = order1[0]\n",
    "        keep.append(i)\n",
    "        xx1 = x1[order[1:]].clamp(min=x1[i].item())\n",
    "        yy1 = y1[order[1:]].clamp(min=y1[i].item())\n",
    "        xx2 = x2[order[1:]].clamp(max=x2[i].item())\n",
    "        yy2 = y2[order[1:]].clamp(max=y2[i].item())\n",
    "\n",
    "        w = (xx2-xx1).clamp(min=0)\n",
    "        h = (yy2-yy1).clamp(min=0)\n",
    "        inter = w*h\n",
    "\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        ids = (ovr<=threshold).nonzero().squeeze()\n",
    "        if ids.numel() == 0:\n",
    "            break\n",
    "        order = order[ids+1]\n",
    "        order1=order.numpy()\n",
    "    return torch.LongTensor(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt(img_path,lbl_path):\n",
    "    image_names=os.listdir(img_path)\n",
    "    image_names=[image.rstrip('.jpg') for image in image_names]\n",
    "    \n",
    "    \n",
    "    lbl_tree = ET.parse(lbl_path)\n",
    "    objs = []\n",
    "    bbox=[]\n",
    "    bboxes=[] \n",
    "    label=[]\n",
    "    labels=[]\n",
    "    \n",
    "    voc_dict = {\n",
    "                        'person':1, 'bird':2, 'cat':3, 'cow':4, 'dog':5, \n",
    "                        'horse':6, 'sheep':7, 'aeroplane':8, 'bicycle':9,\n",
    "                        'boat':10, 'bus':11, 'car':12, 'motorbike':13, 'train':14, \n",
    "                        'bottle':15, 'chair':16, 'diningtable':17, \n",
    "                        'pottedplant':18, 'sofa':19, 'tvmonitor':20\n",
    "                        }\n",
    "    \n",
    "    img = imread(img_path)\n",
    "    h,w,_=img.shape\n",
    "    for obj in lbl_tree.iter(tag='object'):\n",
    "        name = obj.find('name').text\n",
    "        for box in obj.iter(tag='bndbox'):\n",
    "            if name=='person':\n",
    "                xmax = box.find('xmax').text\n",
    "                xmin = box.find('xmin').text\n",
    "                ymax = box.find('ymax').text\n",
    "                ymin = box.find('ymin').text\n",
    "                break\n",
    "            xmax = box.find('xmax').text\n",
    "            xmin = box.find('xmin').text\n",
    "            ymax = box.find('ymax').text\n",
    "            ymin = box.find('ymin').text\n",
    "        attr = (voc_dict[name], float((float(xmin)+float(xmax))/2),float((float(ymin)+float(ymax))/2), float(float(xmax)-float(xmin)), float(float(ymax)-float(ymin)), 1)\n",
    "        attr1=float(xmin)/w,float(ymin)/h,float(xmax)/w,float(ymax)/h\n",
    "        objs.append(attr)\n",
    "        bbox.append(attr1)\n",
    "    box1=torch.Tensor(len(bbox),4)\n",
    "    for i in range(len(bbox)):\n",
    "        box1[i][0]=bbox[i][0]\n",
    "        box1[i][1]=bbox[i][1]\n",
    "        box1[i][2]=bbox[i][2]\n",
    "        box1[i][3]=bbox[i][3]\n",
    "    #bbox=torch.Tensor(bbox)\n",
    "    return box1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
